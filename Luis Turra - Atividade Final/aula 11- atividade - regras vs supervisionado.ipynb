{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM,SpatialDropout1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Pichau\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>local</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id        local sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "\n",
       "                                                text  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = pd.read_csv('Tweets2.csv')\n",
    "tw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Irrelevant    12990\n",
       "Negative      22542\n",
       "Neutral       18318\n",
       "Positive      20832\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw.groupby(['sentiment']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73996, 4)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw.loc[tw['sentiment']=='Irrelevant','sentiment']='Neutral'\n",
    "tw = tw.dropna(subset=['text'])\n",
    "tw.reset_index(drop=True,inplace=True)\n",
    "tw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervisinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(num_words=100)\n",
    "token.fit_on_texts(tw['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = token.texts_to_sequences(tw['text'].values)\n",
    "x = pad_sequences(x,padding = 'post',maxlen = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lber = LabelEncoder()\n",
    "y = lber.fit_transform(tw['sentiment'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np_utils.to_categorical(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49, 39, 38, ...,  0,  0,  0],\n",
       "       [12, 85, 85, ...,  0,  0,  0],\n",
       "       [59,  3,  1, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [65, 65, 16, ...,  0,  0,  0],\n",
       "       [59, 13, 64, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, xtest,y_train,ytest = train_test_split(x,y,test_size = 0.4,random_state = 0)\n",
    "xtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AULA 11 - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "\n",
    "modelo.add(Embedding(input_dim = len(token.word_index), output_dim = 128, input_length = x.shape[1]))\n",
    "modelo.add(SpatialDropout1D(0.2))\n",
    "modelo.add(LSTM(units=196,dropout = 0.2,recurrent_dropout = 0, activation = 'tanh',recurrent_activation = 'sigmoid',unroll = False,use_bias = True))\n",
    "modelo.add(Dense(units = 3,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 100, 128)          4324224   \n",
      "                                                                 \n",
      " spatial_dropout1d_2 (Spatia  (None, 100, 128)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 196)               254800    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 591       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,579,615\n",
      "Trainable params: 4,579,615\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "89/89 [==============================] - 98s 1s/step - loss: 1.0845 - accuracy: 0.4141\n",
      "Epoch 2/5\n",
      "89/89 [==============================] - 99s 1s/step - loss: 1.0837 - accuracy: 0.4156\n",
      "Epoch 3/5\n",
      "89/89 [==============================] - 106s 1s/step - loss: 1.0838 - accuracy: 0.4156\n",
      "Epoch 4/5\n",
      "89/89 [==============================] - 100s 1s/step - loss: 1.0837 - accuracy: 0.4156\n",
      "Epoch 5/5\n",
      "89/89 [==============================] - 100s 1s/step - loss: 1.0837 - accuracy: 0.4156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25990fb3cd0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(x_train,y_train, epochs = 5 , batch_size = 500,verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "925/925 [==============================] - 30s 32ms/step - loss: 1.0811 - accuracy: 0.4234\n",
      "accuracy:  0.4233926832675934\n"
     ]
    }
   ],
   "source": [
    "_,accuracy = modelo.evaluate(xtest,ytest)\n",
    "print('accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3107088 , 0.41157243, 0.27771878],\n",
       "       [0.3107088 , 0.41157243, 0.27771878],\n",
       "       [0.3107088 , 0.41157243, 0.27771878],\n",
       "       ...,\n",
       "       [0.3107088 , 0.41157243, 0.27771878],\n",
       "       [0.3107088 , 0.41157243, 0.27771878],\n",
       "       [0.3107088 , 0.41157243, 0.27771878]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev = modelo.predict(xtest)\n",
    "prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# atividade  - Supervisionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D,Bidirectional,Dropout\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim = len(token.word_index), output_dim = 128, input_length = x.shape[1]))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 100, 128)          4324224   \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 100, 32)           12320     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 50, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,353,379\n",
      "Trainable params: 4,353,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "89/89 [==============================] - 19s 177ms/step - loss: 1.0462 - accuracy: 0.4441\n",
      "Epoch 2/5\n",
      "89/89 [==============================] - 15s 172ms/step - loss: 0.9737 - accuracy: 0.5150\n",
      "Epoch 3/5\n",
      "89/89 [==============================] - 15s 171ms/step - loss: 0.9628 - accuracy: 0.5232\n",
      "Epoch 4/5\n",
      "89/89 [==============================] - 15s 171ms/step - loss: 0.9532 - accuracy: 0.5288\n",
      "Epoch 5/5\n",
      "89/89 [==============================] - 15s 168ms/step - loss: 0.9446 - accuracy: 0.5350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x259a408feb0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs = 5 , batch_size = 500,verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "925/925 [==============================] - 6s 5ms/step - loss: 0.9451 - accuracy: 0.5321\n",
      "accuracy:  0.5320788025856018\n"
     ]
    }
   ],
   "source": [
    "_,accuracy = model.evaluate(xtest,ytest)\n",
    "print('accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44269657, 0.34488168, 0.21242179],\n",
       "       [0.3625981 , 0.4951298 , 0.14227214],\n",
       "       [0.18417417, 0.4594543 , 0.35637158],\n",
       "       ...,\n",
       "       [0.30174053, 0.3422556 , 0.35600385],\n",
       "       [0.11905987, 0.8246252 , 0.05631497],\n",
       "       [0.05312379, 0.7575621 , 0.1893141 ]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev1 = model.predict(xtest)\n",
    "prev1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mas = SentimentIntensityAnalyzer()\n",
    "tw['vader_sentiment'] = ''\n",
    "\n",
    "for y  in range(len(tw.index)):\n",
    "    x = mas.polarity_scores(tw['text'].iloc[y])\n",
    "    del x['compound']\n",
    "    maior = max(x,key = x.get)\n",
    "    tw.loc[y,'vander_sentiment'] = maior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vander_sentiment\n",
       "neg     3657\n",
       "neu    65590\n",
       "pos     4749\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw.groupby(['vander_sentiment']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative    22358\n",
       "Neutral     30983\n",
       "Positive    20655\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw.groupby(['sentiment']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw.loc[tw['vander_sentiment'] =='neu','vander_sentiment'] ='Neutral'\n",
    "tw.loc[tw['vander_sentiment']=='neg','vander_sentiment']='Negative'\n",
    "tw.loc[tw['vander_sentiment']=='pos','vander_sentiment']='Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vander_sentiment\n",
       "Negative     3657\n",
       "Neutral     65590\n",
       "Positive     4749\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw.groupby(['vander_sentiment']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2002, 19904,   452],\n",
       "       [ 1121, 28386,  1476],\n",
       "       [  534, 17300,  2821]], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tw['vander_sentiment']\n",
    "ytest = tw['sentiment']\n",
    "cm = confusion_matrix(ytest,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4487945294340235"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(ytest,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
